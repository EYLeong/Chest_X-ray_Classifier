{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pillow\n",
    "from PIL import Image\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "#OS\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lung_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Lung Dataset Consisting of Infected and Non-Infected.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, purpose, verbose=0):\n",
    "        \"\"\"\n",
    "        Constructor for generic Dataset class - simply assembles\n",
    "        the important parameters in attributes.\n",
    "        \n",
    "        Parameter:\n",
    "        -purpose variable should be set to a string of either 'train', 'test' or 'val'\n",
    "        -verbose takes an int of either 0,1 or 2. 0 will only differentiate between normal and infected, 1 will differentiate\n",
    "            between normal, covid and non-covid while 2 will only differentiate between covid and non-covid\n",
    "        \"\"\"\n",
    "        self.purpose = purpose\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # All images are of size 150 x 150\n",
    "        self.img_size = (150, 150)\n",
    "            \n",
    "        # The dataset has been split in training, testing and validation datasets\n",
    "        self.groups = ['train', 'test', 'val']\n",
    "        \n",
    "        # Path to images for different parts of the dataset\n",
    "        self.dataset_paths = {'train_normal': './dataset/train/normal/',\n",
    "                              'train_infected': './dataset/train/infected/',\n",
    "                              'train_infected_covid': './dataset/train/infected/covid',\n",
    "                              'train_infected_non_covid': './dataset/train/infected/non-covid',\n",
    "                              'test_normal': './dataset/test/normal/',\n",
    "                              'test_infected': './dataset/test/infected/',\n",
    "                              'test_infected_covid': './dataset/test/infected/covid',\n",
    "                              'test_infected_non_covid': './dataset/test/infected/non-covid',\n",
    "                              'val_normal': './dataset/val/normal/',\n",
    "                              'val_infected': './dataset/val/infected/',\n",
    "                              'val_infected_covid': './dataset/val/infected/covid',\n",
    "                              'val_infected_non_covid': './dataset/val/infected/non-covid'}\n",
    "        \n",
    "        self.dataset_numbers = {}\n",
    "        \n",
    "        # Consider normal and infected only\n",
    "        if verbose == 0:\n",
    "            self.classes = {0: 'normal', 1: 'infected'}\n",
    "            \n",
    "            #Populate self.dataset_numbers\n",
    "            for condition in self.classes.values():\n",
    "                key = \"{}_{}\".format(self.purpose, condition)\n",
    "                if condition == \"normal\":\n",
    "                    file_path = self.dataset_paths[key]\n",
    "                    count = len(os.listdir(file_path))\n",
    "                    self.dataset_numbers[key] = count\n",
    "                else:\n",
    "                    key1 = key + \"_covid\"\n",
    "                    key2 = key + \"_non_covid\"\n",
    "                    file_path1 = self.dataset_paths[key1]\n",
    "                    file_path2 = self.dataset_paths[key2]\n",
    "                    count1 = len(os.listdir(file_path1))\n",
    "                    count2 = len(os.listdir(file_path2))\n",
    "                    count = count1 + count2\n",
    "                    self.dataset_numbers[key] = count\n",
    "                       \n",
    "        #Consider normal, covid and non-covid\n",
    "        elif verbose == 1:\n",
    "            self.classes = {0: 'normal', 1: 'covid', 2: 'non_covid'}\n",
    "        \n",
    "            #Populate self.dataset_numbers\n",
    "            for condition in self.classes.values():\n",
    "                if condition == \"normal\":\n",
    "                    key = \"{}_{}\".format(self.purpose, condition)\n",
    "                    file_path = self.dataset_paths[key]\n",
    "                    count = len(os.listdir(file_path))\n",
    "                    self.dataset_numbers[key] = count\n",
    "                else:\n",
    "                    key = \"{}_infected\".format(self.purpose)\n",
    "                    key1 = key + \"_covid\"\n",
    "                    key2 = key + \"_non_covid\"\n",
    "                    file_path1 = self.dataset_paths[key1]\n",
    "                    file_path2 = self.dataset_paths[key2]\n",
    "                    count1 = len(os.listdir(file_path1))\n",
    "                    count2 = len(os.listdir(file_path2))\n",
    "                    self.dataset_numbers[key1] = count1\n",
    "                    self.dataset_numbers[key2] = count2\n",
    "                \n",
    "        #Consider covid and non-covid\n",
    "        elif verbose == 2:\n",
    "            self.classes = {0: 'covid', 1 :'non_covid' }\n",
    "\n",
    "            #Populate self.dataset_numbers\n",
    "            for condition in self.classes.values():\n",
    "                key = \"{}_infected\".format(self.purpose)\n",
    "                key1 = key + \"_covid\"\n",
    "                key2 = key + \"_non_covid\"\n",
    "                file_path1 = self.dataset_paths[key1]\n",
    "                file_path2 = self.dataset_paths[key2]\n",
    "                count1 = len(os.listdir(file_path1))\n",
    "                count2 = len(os.listdir(file_path2))\n",
    "                self.dataset_numbers[key1] = count1\n",
    "                self.dataset_numbers[key2] = count2\n",
    "            \n",
    "        else:\n",
    "            err_msg  = \"Verbose argument only takes in an int of either 0,1 or 2\"\n",
    "            raise TypeError(err_msg)\n",
    "        \n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Descriptor function.\n",
    "        Will print details about the dataset when called.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate description\n",
    "        msg = \"This is the Lung {} Dataset in the 50.039 Deep Learning class project\".format(self.purpose)\n",
    "        msg += \" in Feb-March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for key, val in self.dataset_numbers.items():\n",
    "            if key != 'infected':\n",
    "                file_path = self.dataset_paths[key]\n",
    "            else:\n",
    "                file_path = self.dataset_paths\n",
    "            msg += \" - {}, in folder {}: {} images.\\n\".format(key, file_path, val)\n",
    "        print(msg)\n",
    "        \n",
    "        \n",
    "    def open_img(self, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - class_val variable should be set to 'normal' or 'infected'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \n",
    "        Returns loaded image as a normalized Numpy array.\n",
    "        \"\"\"\n",
    "        group_val = self.purpose\n",
    "        err_msg = \"Error - class_val variable should be set to 'normal', 'infected', 'covid' or 'non_covid'.\"\n",
    "        assert class_val in self.classes.values(), err_msg\n",
    "        \n",
    "        if class_val == 'covid' or class_val == 'non_covid':\n",
    "            class_val = 'infected_' + class_val\n",
    "            \n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n",
    "        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n",
    "        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n",
    "        assert isinstance(index_val, int), err_msg\n",
    "        assert index_val >= 0 and index_val <= max_val, err_msg\n",
    "        \n",
    "        # Open file as before\n",
    "        if class_val != \"infected\":\n",
    "            path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n",
    "        else:\n",
    "            covid_count = len(os.listdir(self.dataset_paths['{}_{}_covid'.format(group_val, class_val)]))\n",
    "            if index_val < covid_count:\n",
    "                path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}_covid'.format(group_val, class_val)], index_val)\n",
    "            else:\n",
    "                index_val = index_val - covid_count\n",
    "                path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}_non_covid'.format(group_val, class_val)], index_val)\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            im = np.asarray(Image.open(f))/255\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    \n",
    "    def show_img(self, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens, then displays image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - class_val variable should be set to 'normal' or 'infected'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \"\"\"\n",
    "        # Open image\n",
    "        im = self.open_img(class_val, index_val)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length special method, returns the number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Length function\n",
    "        return sum(self.dataset_numbers.values())\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getitem special method.\n",
    "        \n",
    "        Expects an integer value index, between 0 and len(self) - 1.\n",
    "        \n",
    "        Returns the image and its label as a one hot vector, both\n",
    "        in torch tensor format in dataset.\n",
    "        \"\"\"\n",
    "        #If we only have 2 classes\n",
    "        if self.verbose == 0 or self.verbose == 2:\n",
    "            first_val = int(list(self.dataset_numbers.values())[0])\n",
    "            if index < first_val:\n",
    "                class_val = self.classes[0]\n",
    "                label = torch.Tensor([1, 0])\n",
    "            else:\n",
    "                class_val = self.classes[1]\n",
    "                index = index - first_val\n",
    "                label = torch.Tensor([0, 1])\n",
    "            im = self.open_img(class_val, index)\n",
    "            im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "          \n",
    "        #If we have 3 classes to consider\n",
    "        elif self.verbose == 1:\n",
    "            first_val = int(list(self.dataset_numbers.values())[0])\n",
    "            second_val = int(list(self.dataset_numbers.values())[1])\n",
    "            if index < first_val:\n",
    "                class_val = self.classes[0]\n",
    "                label = torch.Tensor([1, 0, 0])\n",
    "            elif index >= first_val and index < first_val + second_val:\n",
    "                index = index - first_val\n",
    "                class_val = self.classes[1]\n",
    "                label = torch.Tensor([0,1,0])\n",
    "            else:\n",
    "                index = index-(first_val + second_val)\n",
    "                class_val = self.classes[2]\n",
    "                label = torch.Tensor([0,0,1])\n",
    "            im = self.open_img(class_val, index)\n",
    "            im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "                \n",
    "        else:\n",
    "            raise TypeError(\"Verbose value is not 0,1 or 2\")\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Lung train Dataset in the 50.039 Deep Learning class project in Feb-March 2021. \n",
      "It contains a total of 5216 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - train_normal, in folder ./dataset/train/normal/: 1341 images.\n",
      " - train_infected_covid, in folder ./dataset/train/infected/covid: 1345 images.\n",
      " - train_infected_non_covid, in folder ./dataset/train/infected/non-covid: 2530 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ld_train = Lung_Dataset('train', verbose = 1)\n",
    "ld_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216\n"
     ]
    }
   ],
   "source": [
    "print(len(ld_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_normal': 1341, 'train_infected_covid': 1345, 'train_infected_non_covid': 2530}\n"
     ]
    }
   ],
   "source": [
    "print(ld_train.dataset_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 150, 150])\n",
      "tensor([[[0.0431, 0.0275, 0.0000,  ..., 0.2863, 0.3373, 0.5098],\n",
      "         [0.0706, 0.0471, 0.0000,  ..., 0.3020, 0.3137, 0.4902],\n",
      "         [0.1137, 0.0824, 0.0157,  ..., 0.3255, 0.3098, 0.4784],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0039, 0.0078],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0039, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0039, 0.0039]]])\n",
      "tensor([1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "im, class_oh = ld_train[8]\n",
    "print(im.shape)\n",
    "print(im)\n",
    "print(class_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_test = Lung_Dataset('test', verbose = 1)\n",
    "ld_val = Lung_Dataset('val', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size value to be used (to be decided freely, but set to 4 for demo)\n",
    "bs_val = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(ld_train, batch_size = bs_val, shuffle = True)\n",
    "test_loader = DataLoader(ld_test, batch_size = bs_val, shuffle = True)\n",
    "val_loader = DataLoader(ld_val, batch_size = bs_val, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "0\n",
      "tensor([[[[0.0549, 0.1098, 0.1686,  ..., 0.0118, 0.0000, 0.0039],\n",
      "          [0.1176, 0.1686, 0.2196,  ..., 0.0627, 0.0196, 0.0118],\n",
      "          [0.1882, 0.2314, 0.2706,  ..., 0.1373, 0.0706, 0.0353],\n",
      "          ...,\n",
      "          [0.0353, 0.0392, 0.0431,  ..., 0.0118, 0.0196, 0.0196],\n",
      "          [0.0392, 0.0431, 0.0431,  ..., 0.0118, 0.0157, 0.0196],\n",
      "          [0.0431, 0.0431, 0.0431,  ..., 0.0118, 0.0157, 0.0157]]],\n",
      "\n",
      "\n",
      "        [[[0.4667, 0.2118, 0.1255,  ..., 0.0824, 0.0784, 0.0784],\n",
      "          [0.4824, 0.1725, 0.1961,  ..., 0.0824, 0.0745, 0.0667],\n",
      "          [0.4784, 0.1451, 0.1333,  ..., 0.0824, 0.0902, 0.0980],\n",
      "          ...,\n",
      "          [0.1294, 0.1569, 0.1961,  ..., 0.3020, 0.2627, 0.0941],\n",
      "          [0.1294, 0.1569, 0.1961,  ..., 0.2902, 0.1765, 0.0706],\n",
      "          [0.1294, 0.1608, 0.2000,  ..., 0.2627, 0.1020, 0.0706]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.6588, 0.4588,  ..., 0.0863, 0.0706, 0.0392],\n",
      "          [0.0000, 0.6510, 0.4353,  ..., 0.1098, 0.0824, 0.0392],\n",
      "          [0.0196, 0.6314, 0.4471,  ..., 0.0824, 0.0588, 0.0275],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0039, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0039, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0039, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0941, 0.1020, 0.1020,  ..., 0.1216, 0.1686, 0.2078],\n",
      "          [0.0980, 0.1059, 0.1020,  ..., 0.1333, 0.1804, 0.2196],\n",
      "          [0.1020, 0.1098, 0.1059,  ..., 0.1373, 0.1882, 0.2275],\n",
      "          ...,\n",
      "          [0.0980, 0.0980, 0.1020,  ..., 0.1098, 0.1098, 0.1098],\n",
      "          [0.0980, 0.0980, 0.1020,  ..., 0.1098, 0.1098, 0.1098],\n",
      "          [0.0980, 0.0980, 0.1020,  ..., 0.1098, 0.1098, 0.1098]]],\n",
      "\n",
      "\n",
      "        [[[0.0510, 0.0157, 0.0157,  ..., 0.0706, 0.0706, 0.0745],\n",
      "          [0.0235, 0.0157, 0.0353,  ..., 0.0667, 0.0706, 0.0745],\n",
      "          [0.0314, 0.0314, 0.0549,  ..., 0.0667, 0.0706, 0.0745],\n",
      "          ...,\n",
      "          [0.0549, 0.0549, 0.0392,  ..., 0.0431, 0.0275, 0.0353],\n",
      "          [0.0510, 0.0549, 0.0392,  ..., 0.0431, 0.0314, 0.0314],\n",
      "          [0.0510, 0.0549, 0.0431,  ..., 0.0431, 0.0353, 0.0314]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0549, 0.0275,  ..., 0.1216, 0.1020, 0.0667],\n",
      "          [0.0431, 0.0000, 0.0745,  ..., 0.0118, 0.0078, 0.0078],\n",
      "          [0.0392, 0.0588, 0.0510,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0078, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000]]]])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Typical mini-batch for loop on dataloader (train)\n",
    "for k, v in enumerate(train_loader):\n",
    "    print(\"-----\")\n",
    "    print(k)\n",
    "    print(v[0])\n",
    "    print(v[1])\n",
    "    # Forced stop\n",
    "    break\n",
    "    #assert False, \"Forced stop after one iteration of the for loop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Conv2D: 1 input channel, 8 output channels, 3 by 3 kernel, stride of 1.\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3, 1)\n",
    "        self.fc1 = nn.Linear(87616, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7402, -0.6482],\n",
      "        [-0.7618, -0.6289],\n",
      "        [-0.7417, -0.6468],\n",
      "        [-0.7235, -0.6637],\n",
      "        [-0.7988, -0.5976],\n",
      "        [-0.7516, -0.6379],\n",
      "        [-0.7613, -0.6294],\n",
      "        [-0.7057, -0.6807],\n",
      "        [-0.7129, -0.6738],\n",
      "        [-0.6982, -0.6882],\n",
      "        [-0.7671, -0.6243],\n",
      "        [-0.7569, -0.6332],\n",
      "        [-0.7477, -0.6414],\n",
      "        [-0.7313, -0.6564],\n",
      "        [-0.7472, -0.6419],\n",
      "        [-0.7414, -0.6471],\n",
      "        [-0.7165, -0.6703],\n",
      "        [-0.7204, -0.6666],\n",
      "        [-0.7218, -0.6652],\n",
      "        [-0.8364, -0.5678],\n",
      "        [-0.7819, -0.6116],\n",
      "        [-0.7147, -0.6721],\n",
      "        [-0.7805, -0.6128],\n",
      "        [-0.7543, -0.6355],\n",
      "        [-0.7485, -0.6407],\n",
      "        [-0.7606, -0.6300],\n",
      "        [-0.7434, -0.6453],\n",
      "        [-0.7564, -0.6337],\n",
      "        [-0.7337, -0.6542],\n",
      "        [-0.7400, -0.6483],\n",
      "        [-0.7241, -0.6631],\n",
      "        [-0.7676, -0.6239]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Try model on one mini-batch\n",
    "for batch_idx, (images_data, target_labels) in enumerate(train_loader):\n",
    "    predicted_labels = model(images_data)\n",
    "    print(predicted_labels)\n",
    "    print(target_labels)\n",
    "    # Forced stop\n",
    "    break\n",
    "    #assert False, \"Forced stop after one iteration of the mini-batch for loop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
